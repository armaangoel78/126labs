{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Matrix Sketching #",
   "metadata": {
    "cell_id": "2b3eb215-4821-49f4-ad7c-6615a71e9d2b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Authors:\nv1.0 (2019 Spring) Justin Hong, Vipul Gupta, and Kannan Ramchandran",
   "metadata": {
    "cell_id": "00001-75f489d9-4648-4efc-9440-ee85dea27a41",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Introduction",
   "metadata": {
    "cell_id": "00002-1e3af2a2-0575-44de-ac03-64ef21808c80",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Sketching is an efficient matrix computation technique from randomized linear algebra with a wide range of applications like low-rank approximation, least squares, etc. During sketching, a large matrix is compressed into a smaller matrix by multiplying it by a random matrix. The smaller matrix can be then used as a proxy for the large matrix for efficient (but approximate) computation. In this lab, we will look at sketching-based multiplication of two large matrices.",
   "metadata": {
    "cell_id": "00003-442f7d84-f1b7-4f34-9550-55e4327d57d3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## 1) Sketch Implementations ##",
   "metadata": {
    "cell_id": "00004-361aeda3-3f76-49fd-bfbc-5258574fe573",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Gaussian-sketch and count-sketch are two popular sketching methods in the literature. You will be implementing both of them and analyzing their characteristics and performance on test data. To check your implementation, run the code blocks below the function definition to visualize the expectations and variances of each entry in $\\mathbf S^T\\mathbf S$ for your sketching matrix $\\mathbf S$. They should parallel the results from your HW problem on matrix sketching.",
   "metadata": {
    "cell_id": "00005-cb979805-891b-4bab-9def-fda7d9114741",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00006-bb67f5b9-ac07-47aa-b6a0-0835980c5614",
    "deepnote_cell_type": "code"
   },
   "source": "%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Gaussian Sketch###\nAs seen in your homework, the Gaussian sketch is simply a $d\\times n$ matrix where each element $S_{ij} \\sim \\frac{1}{\\sqrt{d}} Normal(0,1)$. ",
   "metadata": {
    "cell_id": "00007-77f5e4b1-b2e5-46b9-aad4-bed419ecc40f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00008-0e36d9f6-627e-40fe-b378-392f89356877",
    "deepnote_cell_type": "code"
   },
   "source": "def gaussian_sketch(d, n):\n    ## YOUR CODE HERE ##\n    return ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "As we derived in the homework solution, the element-wise expectation and variance of $\\hat{\\textbf{I}} = \\textbf{S}^T\\textbf{S}$ are\n$$\n   \\mathbb{E}[\\hat I_{ij}] = \n\\begin{cases}\n    1, & \\text{if} ~i=j\\\\\n    0, & \\text{otherwise}.\n\\end{cases}\n~~~~~~~~~~\n\\text{Var}[\\hat I_{ij}] = \n\\begin{cases}\n    2/d, & \\text{if} ~i=j\\\\\n    1/d, & \\text{otherwise}.\n\\end{cases}\n$$\nThe above expressions for Gaussian sketch can be verified by generating some nice visualizations of the variance and expectations as shown below. ",
   "metadata": {
    "cell_id": "00009-ce09ddfb-880f-4b89-805a-35475f1fd58b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00010-5df1ec3d-726e-4b60-8796-4c3759d6dddd",
    "deepnote_cell_type": "code"
   },
   "source": "def visualize(fn, n=50, d=30, n_samples=50):\n    # Sample generation\n    sketch_matrices = [fn(d, n) for _ in range(n_samples)]\n    sketch_matrices = np.stack(list(mtx.T.dot(mtx) for mtx in sketch_matrices), axis=2)\n    expect_data = np.mean(sketch_matrices, axis=2)\n    var_data = np.var(sketch_matrices, axis=2)\n    \n    # Visualization\n    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15, 4))\n    fig.tight_layout()\n    \n    im1 = ax1.imshow(expect_data, cmap='YlGn')\n    cbar1 = ax1.figure.colorbar(im1, ax=ax1)\n    cbar1.ax.set_ylabel(\"Expectation\", rotation=-90, va=\"bottom\")\n    \n    im2 = ax2.imshow(var_data, cmap='YlGn')\n    cbar2 = ax2.figure.colorbar(im2, ax=ax2)\n    cbar2.ax.set_ylabel(\"Variance\", rotation=-90, va=\"bottom\")\n    return",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-39fbbb0c-67eb-4f93-a5b2-ddbd922de224",
    "deepnote_cell_type": "code"
   },
   "source": "visualize(gaussian_sketch)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Note how the diagonal entries of the $n\\times n$ matrix $\\mathbf{\\hat I}$ are close to one and non-diagonal entries are close to zero in expectation. Similarly, the variance of each element in $\\mathbf{\\hat I}$ is small (diagonal entries have more variance than non-diagonal entries as predicted by our expression for variance of $\\mathbf{\\hat I}$).",
   "metadata": {
    "cell_id": "00012-278f8530-26f9-43c7-9def-940f1acd37ba",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Count Sketch###\nThe count sketch is slightly more involved.\nFor each column $j\\in [1,n]$ of $\\textbf{S}$, choose a row $i$ uniformly randomly from $[1,d]$ such that \n$$\n   S_{ij}= \n\\begin{cases}\n    1,& \\text{with probability} ~0.5\\\\\n    -1,              & \\text{with probability}~ 0.5\n\\end{cases}\n$$\nand assign $S_{kj} = 0$ for all $k\\neq i$. An example of a $3\\times 8$ count-sketch is \n$$ \\textbf{S} = \\begin{bmatrix} \n    0 & -1 & 1 & 0 & 0 & 1 & 0 & 0\\\\\n    1 & 0 & 0 & 0 & -1 & 0 & -1 & 0\\\\\n    0 & 0 & 0 & -1 & 0 & 0 & 0 & -1\n\\end{bmatrix}\n$$ \n\nNext, we implement the function that generates a count-sketch (this we have implemented for you).",
   "metadata": {
    "cell_id": "00013-16fec601-c077-488f-b540-31364a38606d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00014-7423728a-705c-4844-972d-1de441eb1d55",
    "deepnote_cell_type": "code"
   },
   "source": "def count_sketch(d, n):\n    sketch = np.zeros((d, n))\n    \"\"\"\n    mappings: n-dimesional vector (j-th entry denotes which row-element is non-zero for the j-th column) \n    flips: denotes whether the non-zero element is 1 or -1\n    \"\"\"\n    mappings = np.random.randint(0, d, size=(1, n))\n    flips = np.random.choice([-1,1], size=(1, n))\n    sketch[mappings, np.arange(n)] = flips\n    return sketch",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The element-wise expectation and variance of the matrix $\\hat{\\textbf{I}} = \\textbf{S}^T\\textbf{S}$ are (see homework solution)\n$$\n   \\mathbb{E}[\\hat I_{ij}] = \n\\begin{cases}\n    1, & \\text{if} ~i=j\\\\\n    0, & \\text{otherwise}.\n\\end{cases}\n~~~~~~~~~~\n\\text{Var}[\\hat I_{ij}] = \n\\begin{cases}\n    0, & \\text{if} ~i=j\\\\\n    1/d, & \\text{otherwise}.\n\\end{cases}\n$$\nAgain, we verify the above expressions for count sketch by generating similar visualizations below. ",
   "metadata": {
    "cell_id": "00015-572d6ac1-70d4-47b4-be09-3732d63c395a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00016-fa0e2e19-9a0d-4cd3-a457-c554c103f863",
    "deepnote_cell_type": "code"
   },
   "source": "visualize(count_sketch)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Note how the matrix $\\hat{\\textbf{I}}$ is close to identity in expectation. The variance of the diagonal entries is exactly zero, while the non-diagonal variance is small.",
   "metadata": {
    "cell_id": "00017-3fb3d3df-6c98-48c2-80b2-4384a3dd629b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## 2) Sketched Matrix Multiplication ##",
   "metadata": {
    "cell_id": "00018-f402858b-f5f6-467e-8e3f-720bab26fba7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Next, we will discuss approximate matrix multiplication using sketching. We will compute the matrix product $\\mathbf A^T\\mathbf A$, where $\\mathbf A \\in \\mathcal{R}^{n\\times m}$, using Gaussian and count sketches and compare it with the exact product.\n\nAs can be noted from the expression of variance of $\\mathbf{\\hat I} = \\textbf{S}^T\\textbf{S}$, the accuracy of the sketching-based computation increases as the sketch dimension $d$ increases, that is, $\\mathbf{\\hat I}$ closely approximates $\\mathbf I$. To see how well sketching approximates the matrix product $\\mathbf A^T\\mathbf A$, we will use the Frobenius norm error $\\parallel{}(\\mathbf{SA})^T\\mathbf{SA} - \\mathbf{A}^T\\mathbf A \\parallel_F$ as a metric for distance from the actual product. More specifically, we define percentage error in sketched matrix multiplication as\n$$Error (\\%) = 100\\times\\frac{\\parallel{}(\\mathbf{SA})^T\\mathbf{SA} - \\mathbf{A}^T\\mathbf A \\parallel_F}{\\parallel{}\\mathbf{A}^T\\mathbf A \\parallel_F}.$$\nOur definition of error is one way to capture the element-wise similarity between the two matrices.\n\n(Note: The frobenius norm of a matrix $\\mathbf{M}$ is $\\|\\mathbf{M}\\|_F = \\sqrt{\\sum_{i,j} M_{ij}^2}$).\n\nNext, we will calculate the compute times for sketched matrix multiplication and compare it with the time required for exact multiplication.",
   "metadata": {
    "cell_id": "00019-523b34f6-127d-4afc-9893-8da63af16411",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00020-ec93a412-c2ae-49d8-8388-cbc47d40a976",
    "deepnote_cell_type": "code"
   },
   "source": "# Generate a random matrix A of size n x m\nn = 15000\nm = 1000\nA = np.random.normal(50, 100, size = (n, m))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00021-7faa0720-7ccf-49bd-b247-f5ab8080429a",
    "deepnote_cell_type": "code"
   },
   "source": "def calc_gauss_sketch(d, A):\n    \"\"\"\n    Calculates Gaussian-sketch of A, that is S*A, with sketch-dimension d\n    \"\"\"\n    ##### Write your CODE here (use the function gaussian_sketch). Should take one or two lines at most.\n    return ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Note that Gaussian sketch can be used to find a smaller matrix that can be used as a proxy for $\\mathbf A$, but it does not help in reducing computation time for matrix multiplication. Gaussian sketching $\\mathbf A$ requires $O(mnd)$ time.\n\nHowever, count sketch has a special sparse structure, and we can utilize it to calculate the sketch $\\mathbf C = \\mathbf {SA}$ in $O(mn)$ time. This is done by directly producing the sketched matrix from $A$ rather than producing $S$ explicitly. In the function \"calc_count_sketch\" defined below, use the following algorithm to calculate $\\mathbf C = \\mathbf {SA}$ directly from $\\mathbf A$.\n<br>\n1. Set $\\mathbf C$ to be an all zeros matrix in $\\mathcal{R}^{d\\times m}$.\n2. For each row of $A$, flip the sign with probability 0.5, and then add it to a randomly picked row of $C$.\n\n\nNote that the graphs generated below might vary depending the machine that this notebook is run on. We're expecting count_sketch to be slightly faster or around the same as exact multiplication, but the difference might vary depending on your laptop!",
   "metadata": {
    "cell_id": "00022-c92d440f-e499-4175-a3ec-046143adc0c0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00023-e67f31f0-541a-497e-8733-314e8af7a344",
    "deepnote_cell_type": "code"
   },
   "source": "def calc_count_sketch(d, A):\n    \"\"\"\n    Calculates count-sketch of A, that is S*A, with sketch-dimension d using the algorithm above\n    \"\"\"\n    ##### Write your CODE here \n    \n    return ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00024-195be904-6644-4fa8-9436-c3f0413537b7",
    "deepnote_cell_type": "code"
   },
   "source": "def calc_error(exact_product, sketched_product):\n    \"\"\"\n    Calculate percentage error in Frobenius norm as defined above\n    \"\"\"\n    return 100*np.linalg.norm(exact_product - sketched_product, ord='fro')/np.linalg.norm(exact_product, ord='fro')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "cell_id": "00025-57226412-ac89-4f00-83f6-a87ca1717f41",
    "deepnote_cell_type": "code"
   },
   "source": "def generate_plots(A, num_samples = 5):\n    \"\"\"\n    This function generates time and error plots for sketched matrix multiplication\n    \"\"\"\n    n,m = A.shape\n    sketch_dims = [int(m*x/4) for x in range(5,12,1)]\n    print(\"Sketch dimensions considered\")\n    print(list(sketch_dims))\n    \n    a = len(sketch_dims)\n    g_time = np.zeros(a)\n    g_error = np.zeros(a)\n    c_time = np.zeros(a)\n    c_error = np.zeros(a)\n    iter = 0\n       \n    ## Calculating exact product\n    t1 = time.time()\n    exact_product = (A.T).dot(A)\n    t_exact = time.time() - t1\n    \n    for d in sketch_dims:\n        for _ in range(num_samples):\n            ## Gaussian sketch\n            t2 = time.time()\n            g_sketch = calc_gauss_sketch(d, A)\n            g_product = g_sketch.T.dot(g_sketch)\n            g_time[iter] += time.time() - t2\n            g_error[iter] += calc_error(exact_product, g_product)\n\n            ## Count sketch\n            t3 = time.time()\n            c_sketch = calc_count_sketch(d, A)\n            c_product = c_sketch.T.dot(c_sketch)\n            c_time[iter] += time.time() - t3\n            c_error[iter] += calc_error(exact_product, c_product)\n        iter += 1 \n    \n    ## Averaging error over all sample points\n    g_time = g_time/num_samples\n    g_error = g_error/num_samples\n    c_time = c_time/num_samples\n    c_error = c_error/num_samples\n    \n    fig, ax = plt.subplots(1,1,figsize=(12, 4))\n    ax.plot(sketch_dims, g_error, label=\"Gaussian Sketch\")\n    ax.plot(sketch_dims, c_error, label=\"Count Sketch\")\n    ax.legend(loc=\"best\")\n    ax.set_xlabel(\"Sketch dimension (d)\")\n    ax.set_ylabel(\"Percentage Error\")\n    ax.set_ylim(bottom=0)\n    ax.grid(True)\n    ax.set_title(\"Error for Count and Gaussian sketches\")\n    \n    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12, 4))\n    ax1.plot(sketch_dims, g_time, label=\"Gaussian Sketch\")\n    ax1.plot(sketch_dims, t_exact*np.ones(len(sketch_dims)), label=\"Exact multiplication\")\n    ax1.legend(loc=\"best\")\n    ax1.set_xlabel(\"Sketch dimension (d)\")\n    ax1.set_ylabel(\"Time to compute product (seconds)\")\n    ax1.set_ylim(bottom=0)\n    ax1.grid(True)   \n    ax1.set_title(\"Compute time for Gaussian-sketched Multiply\")\n    \n    ax2.plot(sketch_dims, c_time, label=\"Count Sketch\")\n    ax2.plot(sketch_dims, t_exact*np.ones(len(sketch_dims)), label=\"Exact multiplication\")\n    ax2.legend(loc=\"best\")\n    ax2.set_xlabel(\"Sketch dimension (d)\")\n    ax2.set_ylabel(\"Time to compute product (seconds)\")\n    ax2.set_ylim(bottom=0, top=ax2.get_ylim()[1]*1.15)\n    ax2.grid(True)   \n    ax2.set_title(\"Compute time for Count-sketched Multiply\")\n    \n    plt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00026-0dcc3ddd-8d73-4687-8957-ce35f428fde9",
    "deepnote_cell_type": "code"
   },
   "source": "### This might take a few minutes to run, reduce n_samples to reduce running time (especially while debugging)\ngenerate_plots(A)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Voila! We have improved the compute time for large matrix multiplication using count-sketch by taking advantage of the sketch characteristics. For $\\mathbf A \\in \\mathcal{R}^{n\\times m}, \\mathbf S \\in \\mathcal{R}^{d\\times n}$ and $n \\gg d > m$, determine the time complexity for sketching-based multiplication for both gaussian and count sketches and compare it with the complexity for the exact multiplication $O(m^2n)$. See if it matches the figures generated above. Note that the time complexities given earlier in the lab were only for finding the sketching matrix $\\mathbf A$ and not the time complexity for the whole multiplication.",
   "metadata": {
    "cell_id": "00027-e29e7bf8-15e8-427a-a0fb-cdf9a7b6d93d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "O(mn + nd^2)",
   "metadata": {
    "cell_id": "00028-554a7f01-2778-4d98-a13a-0335ceee4475",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "cell_id": "00029-7925499d-2998-440e-bfdb-8579ce36594d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=689c629a-8a71-4920-b171-415d33c91843' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "deepnote_notebook_id": "466577c0-8d07-44a8-a7a7-de9ff7cb32e5",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}